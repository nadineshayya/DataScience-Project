name: Daily Scrape and Merge

on:
  schedule:
    - cron: '0 0 * * *'  # Runs daily at midnight UTC
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install pandas selenium webdriver_manager beautifulsoup4

      - name: Run AllRecipes Scraper
        run: |
          # Assuming your AllRecipes scraper code is in allrecipes_scraper.py
          python data.py

      - name: Run Recipetineats
        run: |
          # Assuming your AllRecipes scraper code is in allrecipes_scraper.py
          python data1.py

      - name: Run Spruce Eats Scraper
        run: |
          # Assuming your Spruce Eats scraper code is in spruce_eats_scraper.py
          python scraper.py

      - name: Run Data Clean and Merge Script
        run: |
          # Assuming your cleaning and merging code is in clean_merge.py
          python clean_merge.py

      - name: Commit and push any changes
        run: |
          git config user.name "github-actions"
          git config user.email "github-actions@github.com"
          git add .
          git add combined_cleaned.csv
          git commit -m "Daily data scrape and merge update [skip ci]" || echo "Nothing to commit"
          git push
